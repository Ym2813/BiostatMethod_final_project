---
title: "draft_yma"
author: "Anna Ma"
date: "12/12/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(leaps)
library(readr)
library(flexmix)
```

## Data exploration

 **converted variables to per person and docs, beds, etc.** 


```{r, message=FALSE}
cdi = read_csv("cdi.csv") %>%
  janitor::clean_names() %>%
  mutate(crm_1000 = 1000*(crimes/pop),
         pdocs_1000 = 1000*(docs/pop),
         pbeds_1000 = 1000*(beds/pop),
         density_pop = pop/area,
         # convert region to factors and recoded them accordingly 
         region = factor(region, levels = 1:4,
                    labels = c("northeast", "northcentral", "south", "west"))) %>% select(-c(docs,beds))
  
```

### Descriptive statistics of all varaibles
```{r statistic summary}

cdi_descriptive = cdi %>% select(-c(id,cty,state,region))

# Global
skimr::skim(cdi_descriptive) %>% 
  select(-c("skim_type","complete_rate")) %>% 
    mutate(skim_variable = 
             recode(skim_variable, pcincome = "pcincome (in dollars)", totalinc = "totalinc (in million of dollars)"
  )) %>% 
  knitr::kable(
    col.names = c("variable", "n_missing", "mean","sd","min","Q25","median","Q75","max","histogram"),
    caption = "Global Summary", digits = 4)
```

Q: 1. do we need to group them by state or county? group by gounty gives 5000+ rows though...
  2. do we need box plot still? 
  3. again, transfer some variables to "per pop" / "per 1000 pop" ?


### Descriptive analysis

We can use the box plot/ or histogram to check for normality. But I forgot when do we need normality...isn't it for residual??

```{r boxplot}
par(mfrow = c(2,7))

boxplot(cdi$density_pop, main = "density_pop")
boxplot(cdi$area, main = "area")

boxplot(cdi$pop, main = "pop")
boxplot(cdi$pop18, main = "pop18")
boxplot(cdi$pop65, main = "pop65")

boxplot(cdi$pdocs_1000, main = "pdocs_1000")
boxplot(cdi$pbeds_1000, main = "pbeds_1000")

boxplot(cdi$crm_1000,  main = "crm_1000")

boxplot(cdi$hsgrad, main = "hsgrad")
boxplot(cdi$bagrad, main = "bagrad")
boxplot(cdi$poverty, main = "poverty")
boxplot(cdi$unemp,main = "unemp")
boxplot(cdi$pcincome, main = "pcincome")
boxplot(cdi$totalinc, main = "totalinc")

```


### Correlation 

#### Pairwise relationship 

* This gives us an idea of the correlation between each variable, but my old project build whole model first then assessed the correlation. Need Discussion!

```{r}
library(corrplot)
cor(cdi_descriptive) %>% knitr::kable()

library(ggcorrplot)
library(ggstatsplot)
ggstatsplot::ggcorrmat(
  data = cdi_descriptive,
  type = "parametric", 
  colors = c("darkred", "white", "steelblue") # change default colors
)


ggcorrplot(cor(cdi_descriptive), type = "upper",
   lab = TRUE)
```


* Here is the correlation with pairs function. More specific than the heat map above. We can observe the correlation between all the terms here
```{r}
pairs(crm_1000 ~.,data=cdi_descriptive, panel = panel.smooth, upper.panel = NULL, main = "Scatterplot Matrix")
```

#### Marginal distribution ?

```{r}
library(ggplot2)
library(ggExtra)
```

```{r}
marg_den = cdi %>% ggplot(aes(x = density_pop, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_den, type = "histogram", fill="transparent")
```

```{r}
marg_area = cdi %>% ggplot(aes(x = area, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_area, type = "histogram", fill="transparent")
```

```{r}
marg_pop = cdi %>% ggplot(aes(x = pop, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_pop, type = "histogram", fill="transparent")
```

```{r}
marg_pop18 = cdi %>% ggplot(aes(x = pop18, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
# positive correlation
ggMarginal(marg_pop18, type = "histogram", fill="transparent")
```

```{r}
marg_pop65 = cdi %>% ggplot(aes(x = pop65, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_pop65, type = "histogram", fill="transparent")
```

```{r}
marg_pdocs_1000 = cdi %>% ggplot(aes(x = pdocs_1000, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_pdocs_1000, type = "histogram", fill="transparent")
```

```{r}
marg_pbeds_1000 = cdi %>% ggplot(aes(x = pbeds_1000, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_pbeds_1000, type = "histogram", fill="transparent")
```

```{r}
marg_hsgrad = cdi %>% ggplot(aes(x = hsgrad, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') #negative correlation
ggMarginal(marg_hsgrad, type = "histogram", fill="transparent")
```

```{r}
marg_bagrad = cdi %>% ggplot(aes(x = bagrad, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_bagrad, type = "histogram", fill="transparent")
```

```{r}
marg_poverty = cdi %>% ggplot(aes(x = poverty, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
ggMarginal(marg_poverty, type = "histogram", fill="transparent")
```

```{r}
marg_unemp = cdi %>% ggplot(aes(x = unemp, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_unemp, type = "histogram", fill="transparent")
```

```{r}
marg_pcincome = cdi %>% ggplot(aes(x = pcincome, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_pcincome, type = "histogram", fill="transparent")
```

```{r}
marg_totalinc = cdi %>% ggplot(aes(x = totalinc, y = crm_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
ggMarginal(marg_totalinc, type = "histogram", fill="transparent")
```



### Distribution of outcome

```{r}
cdi %>% 
  ggplot(aes(x = crm_1000)) +
  geom_histogram()
```

do we look at the distribution of outcome like this and transform them here? check again

### Counties with unusual rates

```{r}
upper = quantile(cdi$crm_1000, 0.75)
lower = quantile(cdi$crm_1000, 0.25)
IQR = upper - lower
cdi %>% 
  filter(crm_1000 > upper + 1.5*IQR,
         crm_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(cty, crm_1000) %>%
  knitr::kable(digits = 2)
```


## Model! 

**Q: do we need more descriptive analysis, visualization? rate of crime for each state?**


#### Full model predictors

this model used `northeast` as the reference level for region 

```{r}
cdi_model = cdi %>% select(-c(id,cty,state,area,crimes,totalinc))

# use 
full_fit = lm(crm_1000 ~ ., data = cdi_model)
summary(full_fit)

olsrr::ols_plot_resid_qq(full_fit)
olsrr::ols_plot_resid_fit(full_fit)
```


## Transformation
```{r}
lambda = MASS::boxcox(full_fit)
optlam = lambda$x[which.max(lambda$y)]
optlam
```

The lambda from the transformation is 0.5454, so we will try to fit a square root transformation to Y

### New tibble with transformed y
```{r}
cdi_trans = cdi_model %>% mutate(crm_1000_sqr = crm_1000^0.5) %>% select(-c(crm_1000))
```


```{r}
trans_fit = lm(crm_1000_sqr ~ .,data = cdi_trans)
summary(trans_fit)

olsrr::ols_plot_resid_fit(trans_fit)
olsrr::ols_plot_resid_qq(trans_fit)

lambda_trans = MASS::boxcox(trans_fit)
optlam_trans = lambda_trans$x[which.max(lambda_trans$y)]
optlam_trans
```

### Counties with unusual rates

```{r}
upper = quantile(cdi_trans$crm_1000_sqr, 0.75)
lower = quantile(cdi_trans$crm_1000_sqr, 0.25)
IQR = upper - lower

cdi_trans %>% 
  filter(crm_1000_sqr > upper + 1.5*IQR,
         crm_1000_sqr > lower - 1.5*IQR) %>% 
  dplyr::select(crm_1000_sqr) %>% 
  mutate(cty = c("Kings", "St._Loui")) %>% 
  knitr::kable(digits = 2)

# cdi %>% filter(pop == 2300664 | pop == 396685) %>% select(cty,pop)

cdi_trans_without1 = cdi_tans[]
```



#### Backward

```{r}
fit_back = step(trans_fit, direction='backward')
fit_back

olsrr::ols_plot_resid_fit(fit_back)
olsrr::ols_plot_resid_qq(fit_back)
MASS::boxcox(fit_back)
```

Backward: crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region + pbeds_1000 + density_pop

#### forward 

```{r}
fit_forward = step(trans_fit, direction="forward")
fit_forward

olsrr::ols_plot_resid_fit(fit_forward)
olsrr::ols_plot_resid_qq(fit_forward)
MASS::boxcox(fit_forward)
```

lm(formula = crm_1000_sqr ~ pop + pop18 + pop65 + hsgrad + bagrad + 
    poverty + unemp + pcincome + region + pdocs_1000 + pbeds_1000 + 
    density_pop, data = cdi_trans)


#### both

step-wise?

```{r}
fit_both = step(trans_fit, direction='both')
fit_both
```
lm(formula = crm_1000^0.5 ~ pop + pop18 + hsgrad + bagrad + poverty + 
    pcincome + region + pbeds_1000 + density_pop, data = cdi_model)

This gives back the same model as back 
  
## Criterion Based: Adjr2 and Cp

```{r}
# printing the 2 best models of each size. For example, the first two lines: print the best 2 models that have 2 variables (including intercept)

models <- regsubsets(crm_1000_sqr ~., data = cdi_trans,nvmax = 12)
res_sum = summary(models)

par(mfrow=c(1,2))
plot(1:12, res_sum$cp, xlab="No of parameters", ylab="Cp Statistic")
plot(1:12, res_sum$adjr2, xlab="No of parameters", ylab="Adj R2")

mod_s = data.frame(
  Adj.R2 = which.max(res_sum$adjr2),
  CP = which.min(res_sum$cp)
)

get_model_formula <- function(id, object, outcome){
  # get models data
  models <- summary(object)$which[id,-1]
  # Get outcome variable
  #form <- as.formula(object$call[[2]])
  #outcome <- all.vars(form)[1]
  # Get model predictors
  predictors <- names(which(models == TRUE))
  predictors <- paste(predictors, collapse = "+")
  # Build model formula
  as.formula(paste0(outcome, "~", predictors))
}
```

Model chosen by Adj $R^2$:

```{r}
get_model_formula(12, models, "crm_1000_sqr")
```


```{r}
fit_adjr = lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + unemp + pcincome + region+ pbeds_1000 + density_pop, data = cdi_trans)

olsrr::ols_plot_resid_fit(fit_adjr)
olsrr::ols_plot_resid_qq(fit_adjr)
MASS::boxcox(fit_adjr)
```

crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + unemp + pcincome + region+ pbeds_1000 + density_pop

Model chosen by Cp: Same with backward 

```{r}
get_model_formula(11, models, "crm_1000_sqr")
```

crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region+ pbeds_1000 + density_pop


```{r}
fit_Cp = lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region+ pbeds_1000 + density_pop, data=cdi_trans)

olsrr::ols_plot_resid_fit(fit_Cp)
olsrr::ols_plot_resid_qq(fit_Cp)
MASS::boxcox(fit_Cp)
```


```{r}
fit_back_int = lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region + pbeds_1000 + density_pop + pcincome*poverty, data = cdi_trans)
summary(fit_back_int)

olsrr::ols_plot_resid_fit(fit_back_int)
olsrr::ols_plot_resid_qq(fit_back_int)
MASS::boxcox(fit_back_int)
#Cp
olsrr::ols_mallows_cp(fit_back_int,trans_fit) #13.94
#adjr 0.5701

BIC(fit_back_int) #1435.05

back_int_summ =summary(fit_back_int) #1.331
mean(back_int_summ$residuals^2) #1.2598

performance::check_collinearity(fit_back_int)

fit_back_int_without = lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region + pbeds_1000 + density_pop + pcincome*poverty, data = cdi_trans_without)

summary(fit_back_int_without) #adjr 0.5658

# Residual performance
par(mfrow=c(2,2))
olsrr::ols_plot_resid_fit(fit_back_int_without)
olsrr::ols_plot_resid_qq(fit_back_int_without)
MASS::boxcox(fit_back_int_without)

#Cp -38.65??
olsrr::ols_mallows_cp(fit_back_int_without,trans_fit)
#BIC: 1401.441
BIC(fit_back_int_without) 
#MSE
back_int_without_summ =summary(fit_back_int_without) #1.18
mean(back_int_without_summ$residuals^2)
#VIF 
performance::check_collinearity(fit_back_int_without)
```


### Criterion

#### Cp

```{r}
olsrr::ols_mallows_cp(fit_back,trans_fit)
olsrr::ols_mallows_cp(fit_forward,trans_fit)
olsrr::ols_mallows_cp(fit_both,trans_fit)
olsrr::ols_mallows_cp(fit_adjr,trans_fit)
olsrr::ols_mallows_cp(fit_Cp,trans_fit)
```

#### Adj R2

```{r}
summary(fit_back) # 0.5469
summary(fit_forward) #0.5457
summary(fit_both) #0.5469
summary(fit_adjr) #0.5474
summary(fit_Cp) #0.5469
```

#### AIC

```{r}
AIC(fit_back) # 1400.399
AIC(fit_forward) #1404.519
AIC(fit_both) #1400.399
AIC(fit_adjr) # 1400.889
AIC(fit_Cp) # 1400.399
```


#### BIC

```{r}
library(flexmix)
BIC(fit_back) #1453.527
BIC(fit_forward) #1469.908
BIC(fit_both) #1453.527
BIC(fit_adjr) # 1458.104
BIC(fit_Cp) #1453.527
```

#### MSE

```{r}
back_summ =summary(fit_back) #1.331
mean(back_summ$residuals^2)

forward_summ =summary(fit_forward) #1.325
mean(forward_summ$residuals^2)

both_summ =summary(fit_both) #1.331
mean(both_summ$residuals^2)

adjr_summ =summary(fit_adjr) #1.326
mean(adjr_summ$residuals^2)

Cp_summ =summary(fit_Cp) #1.331
mean(Cp_summ$residuals^2)
```


## Check Collinearity

```{r}
performance::check_collinearity(fit_back)
performance::check_collinearity(fit_forward)
performance::check_collinearity(fit_adjr)
performance::check_collinearity(fit_Cp)
```

delete vif larger than 10. Non of them are greater than 10. So all of the models are good, don't have to worry about collinearity.  

## Checking to Outliers and Influential Points

```{r}
olsrr::ols_plot_cooksd_bar(strp_back, print_plot = TRUE)
#remove observations whose cook's D > 0.5
cdi_trans_without = cdi_trans[-c(1, 6),]
```

### Build model without outlier 

Built the without model with **fit_back**

```{r}
fit_back_without = lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region + pbeds_1000 + density_pop, data = cdi_trans_without)

summary(fit_without)

# Residual performance
par(mfrow=c(2,2))
olsrr::ols_plot_resid_fit(fit_back_without)
olsrr::ols_plot_resid_qq(fit_back_without)
MASS::boxcox(fit_back_without)
```

Build the without model with **trans_fit** (full model)

```{r}
trans_fit_without = lm(crm_1000_sqr ~., data = cdi_trans_without)

summary(trans_fit_without)

# Residual performance
par(mfrow=c(2,2))
olsrr::ols_plot_resid_fit(trans_fit_without)
olsrr::ols_plot_resid_qq(trans_fit_without)
MASS::boxcox(trans_fit_without)
```

Built the without model with **fit_adjr**

```{r}
fit_adjr_without = lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + unemp + pcincome + region+ pbeds_1000 + density_pop, data = cdi_trans_without)

summary(fit_adjr_without)

# Residual performance
par(mfrow=c(2,2))
olsrr::ols_plot_resid_fit(fit_adjr_without)
olsrr::ols_plot_resid_qq(fit_adjr_without)
MASS::boxcox(fit_adjr_without)
```

#### Cp for models fit without outlier

```{r}
olsrr::ols_mallows_cp(fit_back_without,trans_fit_without) # 7.047
olsrr::ols_mallows_cp(trans_fit_without,trans_fit_without)# 11
olsrr::ols_mallows_cp(fit_adjr_without,trans_fit_without) # 7.102
```

#### AIC

```{r}
AIC(fit_back_without) # 1371.373
AIC(trans_fit_without) #1375.258
AIC(fit_adjr_without) # 1371.363
AIC(fit_back_int_without) #1344.376
```


#### BIC

```{r}
BIC(fit_back_without) #1424.441
BIC(trans_fit_without) #1440,573
BIC(fit_adjr_without) # 1428.514
BIC(fit_back_int_without) #1401.527
```

#### MSE

```{r}
back_without_summ =summary(fit_back_without) #1.2633
mean(back_without_summ$residuals^2)

trans_without_summ =summary(trans_fit_without) #1.2572
mean(trans_without_summ$residuals^2)

adjr_without_summ =summary(fit_adjr_without) #1.2575
mean(adjr_without_summ$residuals^2)

int_without_summ =summary(fit_back_int_without) #1.18
mean(int_without_summ$residuals^2)

```


# Model Validation

## Compute RMSE, MSPE, adjusted R^2 by cross-validation

Using back and adjr model and data without outlier

```{r warning=FALSE}
library(modelr)
set.seed(1)
cv_df = 
  crossv_kfold(cdi_trans_without, k = 5) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>%
  mutate(
    fit_back = map(train, ~lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region + pbeds_1000 + density_pop, data = .x)),
    trans_fit = map(train, ~lm(crm_1000_sqr ~ pop + pop18 + pop65+ hsgrad + bagrad + poverty + unemp + pcincome + region+ +pdocs_1000+pbeds_1000 + density_pop, data = .x)),
    fit_adjr = map(train, ~lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + unemp + pcincome + region+ pbeds_1000 + density_pop, data = .x)),
    fit_back_int_without = map(train,~lm(crm_1000_sqr ~ pop + pop18 + hsgrad + bagrad + poverty + pcincome + region + pbeds_1000 + density_pop + pcincome*poverty, data = .x))
    ) %>% 
  mutate(
    rmse_back = map2_dbl(fit_back, test, ~rmse(model = .x, data = .y)),
    rmse_full = map2_dbl(trans_fit, test, ~rmse(model = .x, data = .y)),
    rmse_adjr = map2_dbl(fit_adjr, test, ~rmse(model = .x, data = .y)),
    rmse_bain = map2_dbl(fit_back_int_without, test, ~rmse(model = .x, data = .y))) %>%
  mutate(
    mspe_back = map2_dbl(fit_back, test, ~ mean((.y$crm_1000_sqr -predict.lm(.x,.y))^2)),
    mspe_full = map2_dbl(trans_fit, test, ~ mean((.y$crm_1000_sqr -predict.lm(.x,.y))^2)),
    mspe_adjr = map2_dbl(fit_adjr, test, ~ mean((.y$crm_1000_sqr -predict.lm(.x,.y))^2)),
    mspe_bain = map2_dbl(fit_back_int_without, test, ~ mean((.y$crm_1000_sqr -predict.lm(.x,.y))^2))
  ) %>% 
  mutate(
    res_back = map(fit_back, broom::glance %>% as.data.frame),
    res_full = map(trans_fit, broom::glance %>% as.data.frame),
    res_adjr = map(fit_adjr, broom::glance %>% as.data.frame),
    res_bain = map(fit_back_int_without, broom::glance %>% as.data.frame),
    ) %>%
  unnest(res_back, res_full, res_adjr, res_bain) %>%
  dplyr::select(rmse_back,rmse_full,rmse_adjr,rmse_bain,
                mspe_back,mspe_full,mspe_adjr,mspe_bain,
                value.adj.r.squared,value.adj.r.squared1,value.adj.r.squared2,value.adj.r.squared3) %>%
  rename(adjR_back = value.adj.r.squared,
         adjR_full = value.adj.r.squared1,
         adjR_adjr = value.adj.r.squared2,
         adjR_bain = value.adj.r.squared3)

cv_df %>%
  summarise_each(funs(mean( .,na.rm = TRUE))) %>%
  t()
```



## Plot the violin plot
```{r warning=FALSE}
unnest_cd_df = cv_df %>%
  pivot_longer(rmse_back:adjR_bain, 
               names_pattern = "(.*)(....)$", 
               names_to = c("limit", "model")) %>% 
  mutate(limit=ifelse(limit=="", "value", limit)) %>%
  pivot_wider(id_cols = model, 
              names_from = limit, 
              values_from = value, 
              names_repair = "check_unique") %>% 
  unnest(c(rmse_, adjR_)) %>%
  rename(rmse = rmse_,
         adjR = adjR_)
unnest_cd_df %>% ggplot(aes(x = model, y = rmse)) + geom_violin() 
unnest_cd_df %>% ggplot(aes(x = model, y = adjR)) + geom_violin() 
```

```{r}
olsrr::ols_plot_resid_qq(fit_back_int_without)
olsrr::ols_plot_resid_fit(fit_back_int_without)
MASS::boxcox(fit_back_int_without)
```

```{r}
locfit::cp(fit_back_without)
```

```{r}
models1 <- regsubsets(crm_1000_sqr ~., data = cdi_trans_without,nvmax = 12)
res_sum1 = summary(models1)

par(mfrow=c(1,2))
plot(1:12, res_sum1$cp, xlab="No of parameters", ylab="Cp Statistic")
plot(1:12, res_sum1$adjr2, xlab="No of parameters", ylab="Adj R2")
```

